{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset:\n",
    "https://www.kaggle.com/chrisbellec/airlines-tweets-sentiments/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read the dataset in csv\n",
    "tweets = pd.read_csv('./twitter-airline-sentiment/Tweets.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show the first 10 lines\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filter for the category\n",
    "is_positive = tweets['airline_sentiment'].str.contains(\"positive\")\n",
    "is_negative = tweets['airline_sentiment'].str.contains(\"negative\")\n",
    "is_neutral = tweets['airline_sentiment'].str.contains(\"neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some statistics about airlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_tweets = tweets[is_positive]\n",
    "positive_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_tweets = tweets[is_negative]\n",
    "negative_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neutral_tweets = tweets[is_neutral]\n",
    "neutral_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worst_airline = negative_tweets[['airline','airline_sentiment_confidence','negativereason']]\n",
    "worst_airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the rank for the worst airline\n",
    "cnt_worst_airline = worst_airline.groupby('airline', as_index=False).count()\n",
    "cnt_worst_airline.sort_values('negativereason', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the rank for the best airline\n",
    "best_airline = positive_tweets[['airline','airline_sentiment_confidence']]\n",
    "cnt_best_airline = best_airline.groupby('airline', as_index=False).count()\n",
    "cnt_best_airline.sort_values('airline_sentiment_confidence', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the rank for negative reason\n",
    "motivation = negative_tweets[['airline','negativereason']]\n",
    "cnt_bad_flight_motivation = motivation.groupby('negativereason', as_index=False).count()\n",
    "cnt_bad_flight_motivation.sort_values('negativereason', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the useless words:\n",
    "useless_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_bag_of_words_features_filtered(words):\n",
    "    return {\n",
    "        word:1 for word in words \\\n",
    "        if not word in useless_words}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_negative_tweets = []\n",
    "for text in negative_tweets['text']:\n",
    "        tokenized_negative_tweets.append(nltk.word_tokenize(text))\n",
    "        #negative_words.extend(nltk.word_tokenize(text)) \n",
    "        \n",
    "tokenized_negative_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_features = [\n",
    "    (build_bag_of_words_features_filtered(text), 'neg') \\\n",
    "    for text in tokenized_negative_tweets\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(negative_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_positive_tweets = []\n",
    "for text in positive_tweets['text']:\n",
    "        tokenized_positive_tweets.append(nltk.word_tokenize(text))\n",
    "        #negative_words.extend(nltk.word_tokenize(text)) \n",
    "        \n",
    "tokenized_positive_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_features = [\n",
    "    (build_bag_of_words_features_filtered(text), 'pos') \\\n",
    "    for text in tokenized_positive_tweets\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neutral features\n",
    "\n",
    "tokenized_neutral_tweets = []\n",
    "for text in neutral_tweets['text']:\n",
    "        tokenized_neutral_tweets.append(nltk.word_tokenize(text))\n",
    "        #negative_words.extend(nltk.word_tokenize(text)) \n",
    "        \n",
    "tokenized_neutral_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neutral_features = [\n",
    "    (build_bag_of_words_features_filtered(text), 'neu') \\\n",
    "    for text in tokenized_neutral_tweets\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(negative_features)\n",
    "len(positive_features)\n",
    "split = 2000\n",
    "sentiment_classifier = NaiveBayesClassifier.train(positive_features[:split]+negative_features[:split])\n",
    "nltk.classify.util.accuracy(sentiment_classifier, positive_features[:split]+negative_features[:split])*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_features_verify = positive_features[split:]\n",
    "negative_features_verify = negative_features[split:2363]\n",
    "nltk.classify.util.accuracy(sentiment_classifier, positive_features_verify+negative_features_verify)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis on bad flight motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_costumer_service_issue = negative_tweets['negativereason'].str.contains(\"Customer Service Issue\")\n",
    "costumer_service_issue = negative_tweets[is_costumer_service_issue]\n",
    "costumer_service_issue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_costumer_service_issue = []\n",
    "for text in costumer_service_issue['text']:\n",
    "        tokenized_costumer_service_issue.append(nltk.word_tokenize(text))\n",
    "\n",
    "        \n",
    "tokenized_costumer_service_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "costumer_service_issue_features = [\n",
    "    (build_bag_of_words_features_filtered(text), 'service_issue') \\\n",
    "    for text in tokenized_costumer_service_issue\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_late_flight = negative_tweets['negativereason'].str.contains(\"Late Flight\")\n",
    "late_flight = negative_tweets[is_late_flight]\n",
    "late_flight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_late_flight = []\n",
    "for text in late_flight['text']:\n",
    "        tokenized_late_flight.append(nltk.word_tokenize(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "late_flight_features = [\n",
    "    (build_bag_of_words_features_filtered(text), 'late_flight') \\\n",
    "    for text in tokenized_late_flight\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_cant_tell = negative_tweets['negativereason'].str.contains(\"Can't Tell\")\n",
    "cant_tell = negative_tweets[is_cant_tell]\n",
    "cant_tell.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = is_costumer_service_issue | is_late_flight \n",
    "others = negative_tweets[~test]\n",
    "others.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_other = []\n",
    "for text in others['text']:\n",
    "        tokenized_other.append(nltk.word_tokenize(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_features = [\n",
    "    (build_bag_of_words_features_filtered(text), 'other') \\\n",
    "    for text in tokenized_other\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = 1000\n",
    "\n",
    "bad_cause_classifier = NaiveBayesClassifier.train(costumer_service_issue_features[:split]+late_flight_features[:split]+other_features[:split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.classify.util.accuracy(bad_cause_classifier, costumer_service_issue_features[:split]+late_flight_features[:split]+other_features[:split])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "costumer_service_verify = costumer_service_issue_features[split:1400]\n",
    "late_flight_verify = late_flight_features[split:1400]\n",
    "others_verify = other_features[split:1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.classify.util.accuracy(bad_cause_classifier, costumer_service_verify+late_flight_verify+others_verify)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
